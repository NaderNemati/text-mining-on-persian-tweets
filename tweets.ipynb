{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RnnLstm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2ItEqU_-dlA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "aa485694-3a37-44cf-e2bd-8fe5ab3e30bf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPfMwV4qD8v_"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaSJHZIhsbgj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "eece890c-4a7b-49f7-c262-b89f1c274c85"
      },
      "source": [
        "!apt install zipfle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "E: Unable to locate package zipfle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RWpUlMmsnDM"
      },
      "source": [
        "import zipfile\n",
        "data = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_BsM92ftH5s"
      },
      "source": [
        "with zipfile.ZipFile('/content/drive/My Drive/tweet/twitter_sample_tweets.csv.zip', 'r') as zip_ref:\n",
        "  zip_ref.extractall('./twitter_data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww-vfm3FtpS9"
      },
      "source": [
        "f = open(\"./twitter_data/twitter_sample_tweets.csv\", \"r\")\n",
        "df = f.readlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2byR7NVvl--"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Q75G_Qtv4Lc"
      },
      "source": [
        "X_train, Y = train_test_split(df, test_size=0.9980, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbqPgli8_-aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "3f215188-8119-4eb4-c479-6d96b9c51a6a"
      },
      "source": [
        "from itertools import islice\n",
        "for row in islice(X_train, 10):\n",
        "  print(row)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"2019-01-05 22:42:51\",\"  Ù…Ù† Ú©Ù‡ Ø¯Ø§Ø±Ù… ØªÙ…Ø±ÛŒÙ† Ù…ÛŒÚ©Ù†Ù…\",0,2,8438,97,356,1838\n",
            "\n",
            "\"2019-01-03 23:07:20\",\"Ø§Ú¯Ø± Ú©Ø³ÛŒ Ø¹Ø§Ø´Ù‚ #Ø§Ù…Ø§Ù…_Ø²Ù…Ø§Ù†Ø´ Ø¨Ø§Ø´Ø¯ Ø§Ù…Ú©Ø§Ù† Ù†Ø¯Ø§Ø±Ø¯ ÙˆÙ„Ø§ÛŒØª ÙÙ‚ÛŒÙ‡ Ùˆ #Ø±Ù‡Ø¨Ø±Ø´ Ø±Ùˆ Ø¯ÙˆØ³Øª Ù†Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯. #Ø§Ø³ØªØ§Ø¯_Ø´Ø¬Ø§Ø¹ÛŒ \",1,8,39239,0,4,1\n",
            "\n",
            "\"2019-01-06 18:22:32\",\"Ø®Ø¨ Ú†Ø±Ø§ ØªÙˆ ÙÛŒÙ„Ù… Ù‡Ø§ Ø§Ø³Ù… Ú¯Ø±Ø¨Ù‡ Ù‡Ø§ Ø±Ùˆ Ù…ÛŒØ°Ø§Ø±Ù† #Ú©ØªÛŒ ğŸ™„#Ú©Ù„Ù…Ø¨ÙˆØ³\",1,15,201669,0,5,1\n",
            "\n",
            "\"2019-01-31 17:23:54\",\"RT :  Ø³Ù„Ø§Ù… Ø¬Ù†Ø§Ø¨ Ù†Ø®Ø³Øª ÙˆØ²ÛŒØ± Ù…Ø§ Ø§ÛŒØ±Ø§Ù†ÛŒØ§Ù† Ø®ÙˆØ§Ù‡Ø§Ù† Ø­Ú©ÙˆÙ…ØªÛŒ Ú©Ù‡ Ù‚ÙˆØ§Ù†ÛŒÙ† Ø¢Ù† Ø¨Ø± Ú¯Ø±ÙØªÙ‡ Ø§Ø² Ú©ÙˆØ±ÙˆØ´ Ùˆ Ø­Ø§Ú©Ù…Ø§Ù† Ø¢Ù† Ø®Ø±Ø¯ÙˆØ±Ø²Ø§Ù† Ø¨Ø§Ù‡ÙˆØ´Ø§Ù† Ùˆâ€¦\",4,0,27082,0,25,2\n",
            "\n",
            "\"2019-01-28 17:59:37\",\"RT : Ø§Ù„Ø§Ù† Ú©Ù‡ Ø´Ù…Ø§ Ø±Ø§Ø­Øª Ù†Ø´Ø³ØªÛŒØ¯ Ø¯Ø§Ø±ÛŒØ¯ Ø¨Ø§Ø²ÛŒ Ø±Ùˆ Ù…ÛŒØ¨ÛŒÙ†ÛŒØ¯ ØŒ ØªØ±Ø§Ú©ØªÙˆØ±ÛŒØ§ ØªÙˆ Ø´ÙˆÚ©Ù† Ú©Ù‡ Ú†Ù¾Ùˆ ØªØ´ÙˆÛŒÙ‚ Ú©Ù†Ù† ÛŒØ§ Ø±Ø§Ø³ØªÙˆ\",29,0,334,34,59,119\n",
            "\n",
            "\"2019-01-28 11:23:07\",\"RT : Ø§ÙŠÙ†Ø§ÙŠÙŠ ÙƒÙ‡ Ø±Ùˆ Ø§Ø³Ù… \"\"Ø®Ù„ÙŠØ¬ ÙØ§Ø±Ø³\"\" ØºÙŠØ±ØªÙ‰ Ù…ÙŠØ´ÙˆÙ†Ø¯Ø› Ùˆ Ø§Ø² Ù†ÙØª Ùˆ ØµÙŠØ¯ Ùˆ Ú¯Ù…Ø±Ùƒ Ø®Ù„ÙŠØ¬ ÙØ§Ø±Ø³ Ø°Ø±Ù‡ Ø§Ù‰ Ø¨Ù‡ Ø¢Ù†Ù‡Ø§ ØªØ¹Ù„Ù‚ Ù†Ø¯Ø§Ø±Ø¯ Ùˆ Ù‡Ù…Ù‡ Ø§Ø´ Ø¯Ø± Ø§Ù†Ø­ØµØ§Ø±â€¦\",18,0,17804,4622,1932,30769\n",
            "\n",
            "\"2019-01-08 16:09:00\",\"Ø±ÙˆØ² Ø³Ù‡ Ø´Ù†Ø¨Ù‡ Û±Û¸Ø¯ÛŒ  #ØºØ§Ø±Øª_Ø´Ø¯Ú¯Ø§Ù†_Ú©Ø§Ø³Ù¾ÛŒÙ†  Ø¯Ø± #Ø±Ø´ØªØŒ Ø¯Ø± Ø§Ø¹ØªØ±Ø§Ø¶ Ø¨Ù‡ ØºØ§Ø±Øª Ø§Ù…ÙˆØ§Ù„ Ùˆ Ø¯Ø§Ø±Ø§ÛŒÛŒ Ø´Ø§Ù† ØªÙˆØ³Ø· Ù…ÙˆØ³Ø³Ù‡ ØºØ§Ø±ØªÚ¯Ø± Ú©Ø§Ø³Ù¾ÛŒÙ†ØŒ Ø¯Ø± Ù…Ù‚Ø§Ø¨Ù„ Ø¯ÙØªØ± Ø§ÛŒÙ† #Ù…ÙˆØ³Ø³Ù‡ ØªØ¬Ù…Ø¹ Ú©Ø±Ø¯Ù†Ø¯. \",1,3,81575,171,596,6534\n",
            "\n",
            "\"2019-01-09 18:36:15\",\" Ù…ÛŒÚ¯Ù† Ú¯ÙˆÚ¯ÙˆØ´ Ùˆ Ø±Ù‡Ø§ Ø§Ø¹ØªÙ…Ø§Ø¯ÛŒ Ø§Ø²Ø¯ÙˆØ§Ø¬ Ú©Ø±Ø¯Ù†\",0,1,6688,1263,209,32567\n",
            "\n",
            "\"2019-01-10 23:11:28\",\" Ø¯Ø§Ø±Ù‡ Ø¨Ø§ Ø®Ø´Ø®Ø§Ø´ Ø­Ø±Ù Ù…ÛŒØ²Ù†Ù‡\",0,1,17020,1086,974,13069\n",
            "\n",
            "\"2019-01-17 22:12:06\",\" ÙÙ‚Ø· Ø¨Ù„Ø¯Ù† Ø§Ø² Ù…Ø§ Ù¾ÙˆÙ„ Ø¨Ú©Ù†Ù†Ø¯\",0,0,11943,7,9,135\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFTiTAi6Fx1W"
      },
      "source": [
        "data=[]\n",
        "import pandas as pd\n",
        "for i, line in enumerate(X_train):\n",
        "  data.append(line.split(','))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJCR0nCYHKdo"
      },
      "source": [
        "f.close()\n",
        "a=list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ney3esdhHm-V"
      },
      "source": [
        "for i in range(len(data)):\n",
        "  if len(data[i])==8:\n",
        "    a.append(data[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTu4ZQgHIKvm"
      },
      "source": [
        "triandata2=pd.DataFrame(a,columns=['col1','col2','col3','col4','col5','col6','col7','col8'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Wzj-9VbPkOX"
      },
      "source": [
        "traindata=triandata2.loc[:]['col2']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJmuNVErP5kd"
      },
      "source": [
        "import re\n",
        "reviews_ints = []\n",
        "for t in range (len(traindata)):\n",
        "  text = traindata[t]\n",
        "  text = re.sub(r'[^a-zA-Z0-9Ø¢-ÛŒÛ°-Û¹ ]', ' ', text)\n",
        "  text = text.strip()\n",
        "  traindata[t]=text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_6RR46qRoI3"
      },
      "source": [
        "words1=[]\n",
        "for i in range (0,len(traindata)):\n",
        "  words1.append(traindata[i].split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCAFL7iUUD8U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d0c0ec92-aee4-484e-dece-fbd03bdc480e"
      },
      "source": [
        "len(words1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31621"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ltrfw2y8UF0W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "c3395059-434d-4324-9225-aa485cb16fac"
      },
      "source": [
        "words1[10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['RT',\n",
              " 'Ø¯Ùˆ',\n",
              " 'Ø®Ø§Ø·Ø±Ù‡',\n",
              " 'Ø²ÛŒØ¨Ø§',\n",
              " 'Ùˆ',\n",
              " 'Ø¬Ø§Ù„Ø¨',\n",
              " 'Ø§Ø²',\n",
              " 'Ù¾Ù‡Ù„ÙˆØ§Ù†',\n",
              " 'Ù…Ø³Ù„Ù…',\n",
              " 'Ø§Ø³Ú©Ù†Ø¯Ø±',\n",
              " 'ÙÛŒÙ„Ø§Ø¨ÛŒ',\n",
              " 'Ø§Ø²',\n",
              " 'Ø¬Ù‡Ø§Ù†',\n",
              " 'Ù¾Ù‡Ù„ÙˆØ§Ù†',\n",
              " 'ØªØ®ØªÛŒÚ†Ø±Ø§',\n",
              " 'ØªØ®ØªÛŒ',\n",
              " 'Ø­Ø§Ø¶Ø±',\n",
              " 'Ù†Ø´Ø¯',\n",
              " 'Ù†Ù…Ø§ÛŒÙ†Ø¯Ù‡',\n",
              " 'Ù…Ø¬Ù„Ø³',\n",
              " 'Ø´Ø§Ù‡',\n",
              " 'Ø´ÙˆØ¯',\n",
              " 'ÛŒÚ©',\n",
              " 'Ø®Ø§Ø·Ø±Ù‡',\n",
              " 'Ø§Ø²',\n",
              " 'Ú©Ù…Ú©']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnKF80P3UIHy"
      },
      "source": [
        "data=set()\n",
        "for i in range(0,len(words1)):\n",
        "  for j in range(0,len(words1[i])):\n",
        "    data.add(words1[i][j])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYJznBEAVAlI"
      },
      "source": [
        "char_to_int = dict((c,i) for i, c in enumerate(data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIHF6XJFVYF8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "ba070796-5367-476a-b013-5cf397aa1097"
      },
      "source": [
        "!apt install Tokenizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "E: Unable to locate package Tokenizer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sW_3HuUXVkWg"
      },
      "source": [
        "from keras_preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(1000)\n",
        "tokenizer.fit_on_texts(words1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5A0QmVqgc5RR"
      },
      "source": [
        "def partitionlines(lines,maxlen):\n",
        "  data_x=[]\n",
        "  data_y=[]\n",
        "  for line in lines:\n",
        "    words = line\n",
        "    for i in range(0,maxlen):\n",
        "      if i >=len(words)-1:\n",
        "        break\n",
        "      data_x.append(words[0:i+1])\n",
        "      data_y.append(words[i+1])\n",
        "    for i in range(maxlen,len(words)):\n",
        "      if i >=len(words)-1:\n",
        "        break\n",
        "      data_x.append(words[i-maxlen+1:i+1])\n",
        "      data_y.append(words[i+1])\n",
        "  return data_x,data_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6FOgprYfBfH"
      },
      "source": [
        "maxlen = 10\n",
        "lines = tokenizer.texts_to_sequences(words1)\n",
        "data_x,data_y = partitionlines(lines,maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEjGZ_hrfiGL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "35a65ad5-85cc-4a85-dc01-09271fcdbba8"
      },
      "source": [
        "print('x1:',data_x[0])\n",
        "print('y1:',data_y[0])\n",
        "print('x2:',data_x[1])\n",
        "print('y2:',data_y[1])\n",
        "print('x3:',data_x[2])\n",
        "print('y3:',data_y[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x1: [13]\n",
            "y1: 4\n",
            "x2: [13, 4]\n",
            "y2: 76\n",
            "x3: [13, 4, 76]\n",
            "y3: 105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPZSNVaruLf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b344b6d-362c-418a-c804-5fb9f8a091d8"
      },
      "source": [
        "from keras_preprocessing import sequence\n",
        "x_train = sequence.pad_sequences(data_x,maxlen=maxlen)\n",
        "from keras.utils import to_categorical\n",
        "y_train = to_categorical(data_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpumW0p3vFnt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "362ec133-ec23-4cd0-bd2e-616ae53bac0b"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.argmax(y_train[5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "221"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEM-knqQvLb-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "10083beb-8c99-458a-e0fb-0117664251f1"
      },
      "source": [
        "len(y_train[5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UzvMr2kvYZ-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8a90e36-2885-4ba4-b2c2-a6198f466a74"
      },
      "source": [
        "max(data_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aNA_vUpvd7p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc3238bc-051e-4ca5-a308-aca90fc01ee3"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(310370, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUl4XHY0vhw6"
      },
      "source": [
        "import numpy as np\n",
        "np.max(y_train,axis=1)\n",
        "indices = np.arange(0,len(x_train))\n",
        "np.random.shuffle(indices)\n",
        "x_train_shuffled = x_train[indices]\n",
        "y_train_shuffled = y_train[indices]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aavU3QowGEG"
      },
      "source": [
        "x_test = x_train_shuffled[-1000:]\n",
        "x_train_partial = x_train_shuffled[:-1000]\n",
        "y_test = y_train_shuffled[-1000:]\n",
        "y_train_partial = y_train_shuffled[:-1000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3-PSddhxCZ1"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras import  layers\n",
        "from keras import losses\n",
        "from keras import  metrics\n",
        "import keras\n",
        "from keras.layers import Dense, Dropout, Embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2-jPsqHxZ82"
      },
      "source": [
        "def getmodel():\n",
        "  model = Sequential()\n",
        "  model.add(layers.Embedding(1000, 128))\n",
        "  model.add(layers.LSTM(1026,return_sequences=True))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(layers.LSTM(504))\n",
        "  model.add(layers.Dense(y_train.shape[1], activation = 'softmax'))\n",
        "  model.compile(optimizer='adam',loss=losses.categorical_crossentropy, metrics=['accuracy'])\n",
        "\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK0KWjTEyTZQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "157df7de-bfc1-410c-f81d-7f2f551fe184"
      },
      "source": [
        "model = getmodel()\n",
        "history = model.fit(x_train_partial,\n",
        "                    y_train_partial,\n",
        "                    epochs=30,\n",
        "                    batch_size=256)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, None, 128)         128000    \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, None, 1026)        4740120   \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, None, 1026)        0         \n",
            "_________________________________________________________________\n",
            "lstm_10 (LSTM)               (None, 504)               3086496   \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1000)              505000    \n",
            "=================================================================\n",
            "Total params: 8,459,616\n",
            "Trainable params: 8,459,616\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "309370/309370 [==============================] - 90s 291us/step - loss: 5.9028 - accuracy: 0.0547\n",
            "Epoch 2/30\n",
            "309370/309370 [==============================] - 88s 286us/step - loss: 5.6585 - accuracy: 0.0682\n",
            "Epoch 3/30\n",
            "309370/309370 [==============================] - 88s 284us/step - loss: 5.5038 - accuracy: 0.0809\n",
            "Epoch 4/30\n",
            "309370/309370 [==============================] - 87s 281us/step - loss: 5.4001 - accuracy: 0.0907\n",
            "Epoch 5/30\n",
            "309370/309370 [==============================] - 88s 285us/step - loss: 5.3168 - accuracy: 0.0966\n",
            "Epoch 6/30\n",
            "309370/309370 [==============================] - 88s 286us/step - loss: 5.2359 - accuracy: 0.1015\n",
            "Epoch 7/30\n",
            "309370/309370 [==============================] - 87s 281us/step - loss: 5.1539 - accuracy: 0.1057\n",
            "Epoch 8/30\n",
            "309370/309370 [==============================] - 87s 280us/step - loss: 5.0700 - accuracy: 0.1102\n",
            "Epoch 9/30\n",
            "309370/309370 [==============================] - 87s 283us/step - loss: 4.9824 - accuracy: 0.1145\n",
            "Epoch 10/30\n",
            "309370/309370 [==============================] - 87s 281us/step - loss: 4.8914 - accuracy: 0.1201\n",
            "Epoch 11/30\n",
            "309370/309370 [==============================] - 87s 281us/step - loss: 4.7954 - accuracy: 0.1272\n",
            "Epoch 12/30\n",
            "309370/309370 [==============================] - 88s 283us/step - loss: 4.6953 - accuracy: 0.1351\n",
            "Epoch 13/30\n",
            "309370/309370 [==============================] - 87s 281us/step - loss: 4.5893 - accuracy: 0.1453\n",
            "Epoch 14/30\n",
            "309370/309370 [==============================] - 86s 279us/step - loss: 4.4775 - accuracy: 0.1563\n",
            "Epoch 15/30\n",
            "309370/309370 [==============================] - 87s 280us/step - loss: 4.3604 - accuracy: 0.1694\n",
            "Epoch 16/30\n",
            "309370/309370 [==============================] - 86s 278us/step - loss: 4.2419 - accuracy: 0.1839\n",
            "Epoch 17/30\n",
            "309370/309370 [==============================] - 87s 282us/step - loss: 4.1177 - accuracy: 0.1999\n",
            "Epoch 18/30\n",
            "309370/309370 [==============================] - 88s 283us/step - loss: 3.9932 - accuracy: 0.2178\n",
            "Epoch 19/30\n",
            "309370/309370 [==============================] - 88s 283us/step - loss: 3.8657 - accuracy: 0.2366\n",
            "Epoch 20/30\n",
            "309370/309370 [==============================] - 89s 287us/step - loss: 3.7405 - accuracy: 0.2550\n",
            "Epoch 21/30\n",
            "309370/309370 [==============================] - 89s 287us/step - loss: 3.6164 - accuracy: 0.2755\n",
            "Epoch 22/30\n",
            "309370/309370 [==============================] - 88s 284us/step - loss: 3.4947 - accuracy: 0.2966\n",
            "Epoch 23/30\n",
            "309370/309370 [==============================] - 87s 280us/step - loss: 3.3765 - accuracy: 0.3167\n",
            "Epoch 24/30\n",
            "309370/309370 [==============================] - 86s 278us/step - loss: 3.2612 - accuracy: 0.3371\n",
            "Epoch 25/30\n",
            "309370/309370 [==============================] - 86s 277us/step - loss: 3.1522 - accuracy: 0.3559\n",
            "Epoch 26/30\n",
            "309370/309370 [==============================] - 85s 276us/step - loss: 3.0482 - accuracy: 0.3752\n",
            "Epoch 27/30\n",
            "309370/309370 [==============================] - 85s 275us/step - loss: 2.9463 - accuracy: 0.3942\n",
            "Epoch 28/30\n",
            "309370/309370 [==============================] - 85s 276us/step - loss: 2.8511 - accuracy: 0.4123\n",
            "Epoch 29/30\n",
            "309370/309370 [==============================] - 84s 272us/step - loss: 2.7602 - accuracy: 0.4287\n",
            "Epoch 30/30\n",
            "309370/309370 [==============================] - 84s 272us/step - loss: 2.6736 - accuracy: 0.4454\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ck-tY2TKSRz"
      },
      "source": [
        "reverse_word_index = {index:word for word,index in tokenizer.word_index.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTHI56HtLjR-"
      },
      "source": [
        "def predict(input_lines):\n",
        "    input_lines = [line.strip().lower() + ' end' for line in input_lines]\n",
        "    lines = tokenizer.texts_to_sequences(input_lines)\n",
        "    input_x,input_y = partitionlines(lines,maxlen)\n",
        "    model_input_x = sequence.pad_sequences(input_x,maxlen=maxlen)\n",
        "    output_y = model.predict(model_input_x)\n",
        "    output_seq = np.argmax(output_y,axis = 0)\n",
        "    output_lines = [[reverse_word_index[num] for num in inp] for inp in input_x]\n",
        "    predicted_words = [reverse_word_index[num] for num in output_seq]\n",
        "    expected_words = [reverse_word_index[num] for num in input_y]\n",
        "    for i in range(0,len(input_lines)):\n",
        "        print (\"input = :{0}, predicted = {1},expected = {2}\", output_lines[i],predicted_words[i],expected_words[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebSNhqTDnqgW"
      },
      "source": [
        "def wordfromonehot(onehot):\n",
        "    index = np.argmax(onehot)\n",
        "    return reverse_word_index[index]\n",
        "def predict(input_line, count ):\n",
        "    input_line_clean = input_line.strip().lower()\n",
        "    #print(input_lines)\n",
        "    predicted_words = []\n",
        "    input_x= tokenizer.texts_to_sequences([input_line_clean])[0]\n",
        "    for _ in range(0,count):\n",
        "        model_input_x = sequence.pad_sequences([input_x],maxlen=maxlen)\n",
        "        output_y = model.predict(model_input_x)\n",
        "        #print (np.max(output_y))\n",
        "        input_x.append(np.argmax(output_y))\n",
        "        predicted_words.append((wordfromonehot(output_y), np.max(output_y)))\n",
        "    #print(predicted_words)\n",
        "    print (\"input = {0}, predicted = {1}\".format(input_line,predicted_words))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpwOk2xnn9e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "76efbf92-dd33-434d-fbbb-26606c6f3b5a"
      },
      "source": [
        "predict(\"Ø¨Ø§Ø²ÛŒ\",10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input = Ø¨Ø§Ø²ÛŒ, predicted = [('Ø§ÛŒØ±Ø§Ù†', 0.2510396), ('Ùˆ', 0.71295506), ('Ú˜Ø§Ù¾Ù†', 0.5712498), ('ØªÙˆ', 0.30330458), ('Ø¯Ø±', 0.13400902), ('ÛŒÙ‡', 0.04954507), ('Ùˆ', 0.49076903), ('Ø¯Ùˆ', 0.12212429), ('ØªØ§', 0.41119966), ('Ø¯Ùˆ', 0.1203389)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9i0TAKRWpHvA"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFzGDR4YoCaI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e9849284-7a0b-49a5-d19c-d62a1ee78343"
      },
      "source": [
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 0s 345us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6.9973150177001955, 0.11299999803304672]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSbmQp1boFGj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "c41aa832-dd76-47da-f86b-ce49a2056951"
      },
      "source": [
        "x_test_words = []\n",
        "for seq in x_test:\n",
        "    x_test_words.append(' '.join([reverse_word_index[num] for num in seq if num != 0 ]))\n",
        "pred_test = model.predict(x_test)\n",
        "\n",
        "y_test_pred_words = [wordfromonehot(pred) for pred in pred_test]\n",
        "y_act = [wordfromonehot(y) for y in y_test]\n",
        "for i in range(100,110):\n",
        "    #print('input = {0}, pred  = {1}, actual = {2}'.format(x_test_words[i],y_test_pred_words[i],y_act[i]))\n",
        "    predict(x_test_words[i],4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input = ØªÙ†Ù‡Ø§ Ø§Ø­Ù…Ù‚ Ø¨Ù„Ú©Ù‡ Ù‡Ù… Ù‡Ø³ØªÙ† Ù…Ø±Ú¯ Ø¨Ø± Ø®Ø§Ù…Ù†Ù‡ Ø§ÛŒ Ù…Ø±Ú¯, predicted = [('Ø¨Ø±', 0.70684975), ('Ù…Ø±Ú¯', 0.787247), ('Ø¨Ø±', 0.97975105), ('Ø¬Ù…Ù‡ÙˆØ±ÛŒ', 0.32078066)]\n",
            "input = Ø§Ø³Ø±Ø§Ø¦ÛŒÙ„ Ú©Ù‡ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ø¨Ù‡ ØªØ§ Ø±Ù†Ú¯ Ø¯Ù… Ø§ÙˆÙ† Ø±Ùˆ, predicted = [('Ø¨Ù‡', 0.09796313), ('Ú©Ø³ÛŒ', 0.11500972), ('Ù†Ù‡', 0.22940162), ('Ø§ÛŒÙ†Ú©Ù‡', 0.27000952)]\n",
            "input = rt Ø±Ø¦ÛŒØ³ Ù†Ø¯Ø§Ø±Ø¯ Ùˆ Ù‡Ù…Ù‡ Ø¯Ø³Øª, predicted = [('Ùˆ', 0.9425953), ('Ùˆ', 0.49957645), ('Ø²Ù†Ø¯Ú¯ÛŒ', 0.1665816), ('Ù…Ø±Ø¯Ù…', 0.460238)]\n",
            "input = Ø¨ÛŒ Ø®Ø¨Ø±ÛŒ Ø§Ø² Ùˆ Ø±ÙˆØ² Ø¨ÛŒ Ø®Ø¨Ø±ÛŒ Ø§Ø² Ø±ÙˆØ² Ø¨ÛŒ, predicted = [('Ùˆ', 0.38891712), ('Ø§Ø²', 0.22019644), ('Û±Û°', 0.12494301), ('ØªØ§', 0.106594)]\n",
            "input = Ø¯Ø±Ø¯ Ùˆ Ø¯Ø§Ø´ØªÙ† Ø¨Ø¯ Ø§ÛŒÙ† Ø±Ø§ Ùˆ Ú¯ÙØª Ø±Ø§ Ùˆ, predicted = [('Ø±Ø§', 0.22344571), ('Ø¯Ø±', 0.39821452), ('Ù…ÛŒ', 0.20042418), ('Ùˆ', 0.54837537)]\n",
            "input = rt Ù¾Ø³, predicted = [('Ø§Ø²', 0.6341409), ('Ø³Ø§Ù„', 0.13642953), ('Ø§Ø²', 0.28422263), ('Ø§ÛŒØ¬Ø§Ø¯', 0.6309868)]\n",
            "input = rt Ø¨Ø§Ø´ÛŒØ¯ Ú©Ù‡ Ù‡ÛŒÚ† Ú†ÛŒØ² Ø±Ø§ Ø¨Ù‡, predicted = [('Ù…ÛŒ', 0.092724554), ('ØªÙ…Ø§Ù…', 0.058502473), ('Ø²Ù†Ø§Ù†', 0.09503929), ('Ø±Ø§', 0.24515858)]\n",
            "input = Ø¯Ù„ÛŒÙ„ Ø§Ù†ØªØ®Ø§Ø¨ Ù„Ù‡Ø³ØªØ§Ù† Ø¨Ø±Ø§ÛŒ Ø¯Ù„ÛŒÙ„ Ø§Ù†ØªØ®Ø§Ø¨ Ù„Ù‡Ø³ØªØ§Ù†, predicted = [('Ø¯Ø±', 0.686497), ('Ø³ÙˆØ±ÛŒÙ‡', 0.42658982), ('Ø¨Ù‡', 0.38754505), ('Ø²ÛŒØ±', 0.07610931)]\n",
            "input = Ø±Ùˆ Ùˆ Ø²Ù…ÛŒÙ† Ø®ÙˆØ±Ø¯ Ø§Ø² Ø§ÙˆÙ† Ø±ÙˆØ² Ø¨Ù‡ Ø¨Ø¹Ø¯ Ù‡Ù…Ù‡, predicted = [('Ú†ÛŒ', 0.24376452), ('Ø¨Ø¯Ù‡', 0.14009982), ('Ø¨Ù‡', 0.27149808), ('Ø®Ø§Ø·Ø±', 0.09223553)]\n",
            "input = rt Ø§ÛŒÙ† Ø¯Ø®ØªØ± Ø¨Ú†Ù‡, predicted = [('Ø³Ø§Ù„Ù‡', 0.86120254), ('Ø¯Ø±', 0.9928067), ('Ù…Ù‚Ø§Ø¨Ù„', 0.95125705), ('ÛŒ', 0.8348639)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj9AOr7roHfZ"
      },
      "source": [
        "model.save('outlook_pred.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PRcy5nsvXWc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}